{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('../Python-modules/') #For bee_helpers and file_helpers \n",
    "from bee_helpers import calc_trip_lengths, get_forager_bee_ids, get_random_bee_ids, get_all_bee_ids\n",
    "from file_helpers import delete_detection_caches_for_date, detections_to_presence, detections_to_presence_locations, create_presence_cache_filename, create_presence_cache_filename, cache_location_prefix, cache_detections_from_database, detections_to_presence_locations_front, detections_to_presence_locations_back, cache_death_dates, last_days_caches\n",
    "from datetime import timedelta, datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_start_day = datetime(2016, 7, 20) # TODO: those are dates of first and last detections\n",
    "experiment_end_day = datetime(2016, 9, 19)   # consider making the period smaller\n",
    "\n",
    "datetime_start = datetime(2016, 7, 24)\n",
    "num_days_to_process = 2\n",
    "number_last_days = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "observ_period = timedelta(hours=1)\n",
    "num_observ_periods = 24 #hours in day\n",
    "detection_confidence_requirement = 0.99 #note: 0.99 is pretty high\n",
    "num_intervals_per_hour = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a subset of bees to analyze (e.g. all of them)\n",
    "(bee_ids_as_ferwar_format, bee_ids_as_beesbookid_format) = get_all_bee_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning at 2016-07-24 00:00:00\n",
      "Getting hour #0, beginning at 2016-07-24_00:00:00\n",
      "Getting the data took: 0:02:06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/24 [02:53<1:06:36, 173.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the csv took: 0:00:47\n",
      "Getting hour #1, beginning at 2016-07-24_01:00:00\n",
      "Getting the data took: 0:02:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/24 [06:18<1:09:20, 189.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the csv took: 0:00:53\n",
      "Getting hour #2, beginning at 2016-07-24_02:00:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8b270d8ec792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mcache_detections_from_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_day\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserv_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_observ_periods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_confidence_requirement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mdetections_to_presence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_observ_periods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_day\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_intervals_per_hour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbee_ids_as_ferwar_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mnt/janek/Beesbook-life/Python-modules/file_helpers.py\u001b[0m in \u001b[0;36mcache_detections_from_database\u001b[0;34m(datetime_start, observ_period, num_observ_periods, detection_confidence_requirement)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetection_confidence_requirement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             coerce_float=False)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m    312\u001b[0m     return pandas_sql.read_query(\n\u001b[1;32m    313\u001b[0m         \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         parse_dates=parse_dates, chunksize=chunksize)\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1413\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1414\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1376\u001b[0m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/encodings/utf_8.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "force_refresh = True\n",
    "\n",
    "for i in range(num_days_to_process):\n",
    "    start_day = datetime_start+timedelta(days=i)\n",
    "   \n",
    "    if (start_day < experiment_start_day):\n",
    "        print(start_day, \" is before expertiment start day (\", experiment_start_day, \"), skipping!\")\n",
    "        continue\n",
    "\n",
    "    if (start_day > experiment_end_day):\n",
    "        print(start_day, \" is after expertiment end day (\", experiment_end_day, \"), quitting!\")\n",
    "        break\n",
    "\n",
    "    \n",
    "    (csv_name, csv_path) = create_presence_cache_filename(num_observ_periods, start_day, num_intervals_per_hour)\n",
    "    presence_file = Path(csv_path)\n",
    "    \n",
    "    \n",
    "    if (presence_file.exists() and force_refresh==False):\n",
    "        print(\"File \"+ csv_name + \" already exists, moving on\")\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    cache_detections_from_database(start_day, observ_period, num_observ_periods, detection_confidence_requirement)    \n",
    "    detections_to_presence(num_observ_periods, start_day, num_intervals_per_hour, bee_ids_as_ferwar_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "for i in range(num_days_to_process):\n",
    "  \n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    cache_detections_from_database(start_day, observ_period, num_observ_periods, detection_confidence_requirement)    \n",
    "    detections_to_presence(num_observ_periods, start_day, num_intervals_per_hour, bee_ids_as_ferwar_format)\n",
    "    detections_to_presence_locations(num_observ_periods, start_day, num_intervals_per_hour, bee_ids_as_ferwar_format)\n",
    "    detections_to_presence_locations_front(num_observ_periods, start_day, num_intervals_per_hour, bee_ids_as_ferwar_format)\n",
    "    detections_to_presence_locations_back(num_observ_periods, start_day, num_intervals_per_hour, bee_ids_as_ferwar_format)\n",
    "    delete_detection_caches_for_date(start_day.strftime(\"%Y-%m-%d\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-19 00:00:00  is before expertiment start day ( 2016-07-20 00:00:00 ), skipping!\n",
      "File PRESENCE-2016-07-20_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-07-21_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-07-22_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-07-23_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-07-24_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-07-25_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-07-26_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-07-27_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-07-28_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-07-29_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-07-30_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-07-31_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-01_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-02_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-03_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-04_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-05_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-06_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-07_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-08_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-09_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-10_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-11_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-12_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-13_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-14_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-15_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-16_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-17_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-18_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-19_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-20_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-21_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-22_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-23_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-24_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-25_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-26_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-27_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-28_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-29_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-30_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-08-31_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-09-01_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-09-02_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-09-03_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-09-04_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-09-05_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-09-06_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-09-07_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-09-08_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-09-09_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-09-10_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-09-11_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-09-12_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-09-13_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-09-14_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-09-15_00_num_hours_24_int_size_60.csv already exists, moving on\n",
      "File PRESENCE-2016-09-16_00_num_hours_24_int_size_60.csv already exists, moving on\n"
     ]
    }
   ],
   "source": [
    "force_refresh = False\n",
    "\n",
    "for i in range(num_days_to_process):\n",
    "    start_day = datetime_start+timedelta(days=i)\n",
    "   \n",
    "    if (start_day < experiment_start_day):\n",
    "        print(start_day, \" is before expertiment start day (\", experiment_start_day, \"), skipping!\")\n",
    "        continue\n",
    "\n",
    "    if (start_day > experiment_end_day):\n",
    "        print(start_day, \" is after expertiment end day (\", experiment_end_day, \"), quitting!\")\n",
    "        break\n",
    "\n",
    "    \n",
    "    (csv_name, csv_path) = create_presence_cache_filename(num_observ_periods, start_day, num_intervals_per_hour)\n",
    "    presence_file = Path(csv_path)\n",
    "    \n",
    "    #TODO: do the same for Detections \n",
    "    \n",
    "    if (presence_file.exists() and force_refresh==False):\n",
    "        print(\"File \"+ csv_name + \" already exists, moving on\")\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    cache_detections_from_database(start_day, observ_period, num_observ_periods, detection_confidence_requirement)    \n",
    "    detections_to_presence(num_observ_periods, start_day, num_intervals_per_hour, bee_ids_as_ferwar_format)\n",
    "    detections_to_presence_locations(num_observ_periods, start_day, num_intervals_per_hour, bee_ids_as_ferwar_format)\n",
    "    detections_to_presence_locations_front(num_observ_periods, start_day, num_intervals_per_hour, bee_ids_as_ferwar_format)\n",
    "    detections_to_presence_locations_back(num_observ_periods, start_day, num_intervals_per_hour, bee_ids_as_ferwar_format)\n",
    "    delete_detection_caches_for_date(start_day.strftime(\"%Y-%m-%d\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a table with the death dates for the bees (by saving the last day alive for each one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bee alive states\n",
      "Saved last day alive for all bees\n"
     ]
    }
   ],
   "source": [
    "# Creating the last_day_alive file for the bees. Should not be required to run again unless the file got lost.\n",
    "cache_death_dates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating \"2 days before death\" tables for all cached files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2855 [00:27<7:15:41,  9.17s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8021b03f8855>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlast_days_caches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_observ_periods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_intervals_per_hour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_last_days\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mnt/janek/Beesbook-life/Python-modules/file_helpers.py\u001b[0m in \u001b[0;36mlast_days_caches\u001b[0;34m(num_hours, num_intervals_per_hour, number_last_days)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0mnew_presence_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpresence_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mnew_presence_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_presence_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_presence_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0mnew_locations_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocations_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0mnew_locations_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_locations_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_locations_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0mnew_locations_front_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocations_front_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m     \"\"\"\n\u001b[1;32m    813\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "last_days_caches(num_observ_periods, num_intervals_per_hour, number_last_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_bee_lifespan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

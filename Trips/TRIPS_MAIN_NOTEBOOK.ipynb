{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mi/rrszynka/mnt/janek/Beesbook-life/Trips\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_presence_locations_cache_filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8bc9d1ad7737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Python-modules/'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#For bee_helpers and file_helpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbee_helpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalc_trip_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_trip_starts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_forager_bee_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_random_bee_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_all_bee_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfile_helpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcache_location_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetections_to_presence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetections_to_presence_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_presence_cache_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_presence_locations_cache_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_presence_cache_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_location_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_presence_locations_cam_cache_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'create_presence_locations_cache_filename'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#TODO: cleanup imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import math\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "import sys \n",
    "sys.path.append('../Python-modules/') #For bee_helpers and file_helpers \n",
    "from bee_helpers import calc_trip_lengths, calc_trip_starts, get_forager_bee_ids, get_random_bee_ids, get_all_bee_ids\n",
    "from file_helpers import cache_location_prefix, detections_to_presence, detections_to_presence_locations, create_presence_cache_filename, create_presence_locations_cache_filename, create_presence_cache_filename, cache_location_prefix, create_presence_locations_cam_cache_filename\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import bb_utils\n",
    "import bb_utils.meta\n",
    "import bb_utils.ids\n",
    "import bb_backend\n",
    "from bb_backend.api import FramePlotter, VideoPlotter\n",
    "from bb_backend.api import get_plot_coordinates, transform_axis_coordinates, get_image_origin\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "bb_backend.api.server_adress = 'localhost:8000'\n",
    "connect_str = \"\"\"dbname='beesbook' user='reader' host='tonic.imp.fu-berlin.de' \n",
    "                 password='' application_name='mehmed'\"\"\"\n",
    "\n",
    "meta = bb_utils.meta.BeeMetaInfo()\n",
    "BeesbookID = bb_utils.ids.BeesbookID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constant parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Constants cannot be defined twice! (here and DB_TO_DETECTIONS)\n",
    "#TODO: Remove unused consts\n",
    "#potential solution: google jupyter magic/jupyter constant definition \n",
    "\n",
    "\n",
    "#Parameters for loading data, currently using known date of 23th, august 2016)\n",
    "num_hours = 24\n",
    "num_days_to_process = 60\n",
    "\n",
    "datetime_start = datetime(2016, 7, 20)\n",
    "\n",
    "#Parameters for presenting data\n",
    "bin_size_in_hours = 24\n",
    "\n",
    "#Hyperparameters for the data wrangling process\n",
    "num_intervals_per_hour = 60\n",
    "num_intervals_per_minute = num_intervals_per_hour/60\n",
    "rolling_window_size = 5\n",
    "\n",
    "total_num_intervals = (num_intervals_per_hour*num_hours)\n",
    "\n",
    "print(\"Starting from\", datetime_start, \"with number of hours:\", num_hours)\n",
    "print(\"Bin size for the trip lengths plot:\", bin_size_in_hours)\n",
    "print(\"Number of intervals per hour:\", num_intervals_per_hour)\n",
    "print(\"Rolling win size:\", rolling_window_size)\n",
    "#(NOTE: First detections are on 20.07.2016, last are 19.09.2016 (3 months duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a group of bees to work on and calculate their ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Filter out dead bees\n",
    "#TODO: Move this out to a function \n",
    "\n",
    "#Get all bees/n random bees/forager group 20\n",
    "(bee_ids_as_ferwar_format, bee_ids_as_beesbookid_format) = get_all_bee_ids()\n",
    "\n",
    "#Calculate the ages for each bee\n",
    "bee_days_since_birth = [] \n",
    "\n",
    "#TODO: calculate ages from the dataframe later (after filtering)\n",
    "for id in bee_ids_as_beesbookid_format:\n",
    "    bee_days_since_birth.append((datetime_start - meta.get_hatchdate(id)).days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a PRESENCE.csv cache (saved from the DB_TO_DETECTIONS notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_dfs = []\n",
    "for i in tqdm_notebook(range(0, num_days_to_process)):\n",
    "    start_day = datetime_start+timedelta(days=i)\n",
    "    (csv_name, csv_path) = create_presence_cache_filename(num_hours, start_day, num_intervals_per_hour)\n",
    "    file = Path(csv_path)\n",
    "    if file.exists() == False:\n",
    "        print(\"File \"+ csv_name + \"Doesn't exist, stopping entire operation\")\n",
    "        break\n",
    "    new_presence_df = pd.read_csv(csv_path).drop(columns=['id','Unnamed: 0'])\n",
    "    presence_dfs.append(new_presence_df)\n",
    "presence_df = pd.concat(presence_dfs, axis=1)\n",
    "print(\"Done, final shape: \" + str(presence_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_pres_by_bee = presence_df.sum(axis=1)\n",
    "sum_pres_by_bee = sum_pres_by_bee.to_frame()\n",
    "sum_pres_by_bee.columns = ['presence_score_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_pres_by_bee.presence_score_total.hist(bins=300, figsize=(30,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying rolling median to filter presence table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing for rolling median\n",
    "num_nans_to_clean = math.floor(rolling_window_size/2)\n",
    "\n",
    "#apply copies of the first and last column as offset to prepare for the rolling window\n",
    "first_col = presence_df.iloc[:, :1]\n",
    "last_col = presence_df.iloc[:, -1:]\n",
    "\n",
    "presence_df_with_offset = presence_df.iloc[:, 1:]\n",
    "\n",
    "for i in range(0,num_nans_to_clean):\n",
    "    presence_df_with_offset = pd.concat([first_col, presence_df_with_offset, last_col] ,axis=1)\n",
    "    \n",
    "\n",
    "# Applying rolling median window, to filter out noise in the dataframe\n",
    "rolled = presence_df_with_offset.rolling(window=rolling_window_size,center=True,axis=1).median()\n",
    "\n",
    "#clean up to get rid of the NaNs\n",
    "rolled = rolled.iloc[:, num_nans_to_clean:-num_nans_to_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_intervals_per_day = int(rolled.shape[1]/num_days_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_intervals_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolled.shape\n",
    "# rolled.to_csv(cache_location_prefix+'Other/'+'all_bees_presence_rolled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_combined = rolled.iloc[:num_intervals_per_day,:]\n",
    "presence_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_combined = rolled.iloc[:num_intervals_per_day,:]\n",
    "for i in tqdm(range(2, num_days_to_process)):\n",
    "    presence_combined = presence_combined + rolled.iloc[(i-1)*num_intervals_per_day:i*num_intervals_per_day,:]\n",
    "presence_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_combined.sum(axis=0).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_combined.sum(axis=0).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_combined.sum(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_stat_df = (presence_combined.sum(axis=0) / int(rolled.shape[0])).to_frame()\n",
    "pres_stat_df.columns = ['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_stat_df.plot.scatter(figsize=(30,15), x=0,y=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting trip lenghts for each bee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: do we really need a variable for total_num_intervals? (test rolled_shape, it might have the same information)\n",
    "#TODO: might be broken unless total_num_intervals is improved on or eliminated \n",
    "\n",
    "rolled_trip_lengths = calc_trip_lengths(rolled, total_num_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use diff to identify beeentries (with 1) and beeexits (with -1)\n",
    "#(sum_of_abs / 2) gives us the presumed number of trips a bee takes \n",
    "\n",
    "diffed = rolled.diff(axis=1)\n",
    "diffed.iloc[:,0] = 0 #clean out a column of NaNs that was created by diff\n",
    "summed = diffed.abs().sum(axis=1) / 2\n",
    "summed[summed > 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this cell seems to be there for the purpose of caching TRIPS, but doesn't work \n",
    "# verify if it's the way we want trips to be cached and either change or fix it \n",
    "\n",
    "trips_df = presence_df['id'] #for combining results in one table\n",
    "\n",
    "\n",
    "#for loop config\n",
    "bin_starttime = datetime_start\n",
    "num_intervals_per_bin = num_intervals_per_hour*bin_size_in_hours\n",
    "total_num_bins = int(num_hours / bin_size_in_hours)\n",
    "\n",
    "print(\"num_intervals_per_bin: \", num_intervals_per_bin, \"total_num_bins: \", total_num_bins)\n",
    "\n",
    "for bin_nr in range(total_num_bins): \n",
    "    \n",
    "    start_index = bin_nr*num_intervals_per_bin\n",
    "    end_index = start_index + num_intervals_per_bin\n",
    "    \n",
    "    new_bin = diffed.iloc[:, start_index:end_index]\n",
    "    \n",
    "    #limit down to the right bin:\n",
    "    #read num_intervals_per_hour*bin_size_per_hour columns (as each column represents one interval)\n",
    "    \n",
    "    summed = new_bin.abs().sum(axis=1) / 2\n",
    "    summed.name = bin_nr\n",
    "    trips_df = pd.concat([trips_df,summed],axis=1) #add this interval to the trips table\n",
    "    #update loop index\n",
    "    \n",
    "\n",
    "# TODO:use a new variable instead of reusing it\n",
    "# Change values to amount per hour instead of per interval\n",
    "trips_df = trips_df * 3600 / num_intervals_per_hour\n",
    "\n",
    "#TODO: is this the state we want to save?\n",
    "#saving (name still incomplete)\n",
    "date_string = (datetime_start).strftime(\"%Y-%m-%d_%H:%M:%S\")+\".csv\"\n",
    "\n",
    "trips_df.to_csv(cache_location_prefix+'TRIPS-'+date_string+'-'+'h'+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 1: Histogram of the distribution of trip lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in rolled_trip_lengths for item in sublist]\n",
    "flat_series = pd.Series(flat_list)\n",
    "\n",
    "ax = plt.figure(figsize=(30,10))\n",
    "plt.title('Histogram of trip lengths, number of intervals per hour = '+str(num_intervals_per_hour)+', unrolled')\n",
    "(flat_series[flat_series<100]/num_intervals_per_minute).hist(log=False, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 1a: Histogram of the distribution of trip lenghts, cut off at >50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.title('Histogram of trip lengths, num_intvs = '+str(num_intervals_per_hour)+', roll_winsize = '+str(rolling_window_size)+'')\n",
    "flat_series_filtered = flat_series[flat_series<100]\n",
    "(flat_series_filtered/num_intervals_per_minute).hist(bins=100, log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 2: bee age vs amount of trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: calculate ages from the dataframe later (after filtering)\n",
    "bee_days_since_birth = [] \n",
    "bee_bdays = [] \n",
    "\n",
    "for i in tqdm(range(num_days_to_process)):\n",
    "    start_day = datetime_start+timedelta(days=i)\n",
    "    for id in bee_ids_as_beesbookid_format:\n",
    "        bee_bdays.append(meta.get_hatchdate(id))\n",
    "        bee_days_since_birth.append((start_day - meta.get_hatchdate(id)).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_trips = []\n",
    "for i in tqdm(range(num_days_to_process)):\n",
    "    daily_trips.append(diffed.iloc[:,i*1400:(i+1)*1440].abs().sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trips_per_hiveday = pd.concat(daily_trips, axis=1)\n",
    "num_trips_per_hiveday = num_trips_per_hiveday[num_trips_per_hiveday.abs().sum(axis=1) > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lives_from_detections_df = pd.read_csv('../../caches/Other/lives_from_detections_df.csv', \n",
    "                                       index_col='bee_id', \n",
    "                                       parse_dates=['min', 'max'])\n",
    "lives_from_detections_df = lives_from_detections_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trips_per_hiveday.index.rename('bee_id', inplace = True)\n",
    "num_trips_per_hiveday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensuring lives_from_detections and num_trips_per_hiveday have only the rows they both share ('inner')\n",
    "temp_df = num_trips_per_hiveday.join(lives_from_detections_df, how='inner')\n",
    "lives_from_detections = temp_df[['min','max','lifespan']]\n",
    "num_trips_per_hiveday = temp_df.drop(columns=['min','max','lifespan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_by_ages = num_trips_per_hiveday*0 #create a DataFrame with the same shape and labels, but empty\n",
    "trips_by_ages.shape\n",
    "day_0 = datetime(2016, 7, 19)\n",
    "\n",
    "for day in tqdm(trips_by_ages.columns):\n",
    "    for bee in trips_by_ages.index: #of a bee\n",
    "        bee_birth_date = lives_from_detections_df.loc[bee]['min']\n",
    "        if lives_from_detections_df.loc[bee]['lifespan'] < day:\n",
    "            trips_by_ages.loc[bee, day] = np.nan\n",
    "        else:\n",
    "            bee_life_day = bee_birth_date+timedelta(day)\n",
    "            experiment_day = (bee_life_day - day_0).days\n",
    "            if experiment_day > 58:\n",
    "                continue\n",
    "            trips_by_ages.loc[bee, day] = num_trips_per_hiveday.loc[bee, experiment_day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_by_ages.sum() / (trips_by_ages.isnull() == False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "trips_by_ages_per_bee = trips_by_ages.sum()/(trips_by_ages.isnull() == False).sum()\n",
    "ax = sns.lineplot(data=trips_by_ages_per_bee)\n",
    "ax.set_title('Avg. trips per day ')\n",
    "ax.set_xlabel('Day of life')\n",
    "ax.set_ylabel('Avg. number of trips on a day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, trips_by_ages.shape[0])\n",
    "ax = sns.lineplot(data=trips_by_ages.iloc[i])\n",
    "ax.set(ylim=[-3,200], xlim=[0,60])\n",
    "ax.set_xlabel('Day of life')\n",
    "ax.set_ylabel('Number of trips')\n",
    "ax.set_title('Number of trips by day, for bee #'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foragers_from_groups = pd.read_pickle('/home/mi/rrszynka/mnt/janek/caches/Other/foragers_from_groups.pkl').drop(columns=['bee_id'])\n",
    "\n",
    "forager_lives = pd.merge(lives_from_detections_df, foragers_from_groups, how='inner', on='bee_id')\n",
    "\n",
    "\n",
    "forager_lives.rename(columns={'min':'born', 'max':'died', 'date': 'foraging_min_date'}, inplace=True)\n",
    "forager_lives_short = forager_lives[~forager_lives.index.duplicated()]\n",
    "\n",
    "\n",
    "foraging_max_date = forager_lives[~forager_lives.index.duplicated(keep='last')].foraging_min_date.rename('foraging_max_date')\n",
    "forager_lives_short = pd.merge(forager_lives_short, pd.DataFrame(foraging_max_date), how='inner', on='bee_id')\n",
    "forager_lives_short = forager_lives_short.drop(columns=[\"group_id\", \"location\"])\n",
    "\n",
    "forager_lives_short['foraging_min_age'] = (forager_lives_short.foraging_min_date - forager_lives_short.born)\n",
    "forager_lives_short['foraging_max_age'] = (forager_lives_short.foraging_max_date - forager_lives_short.born)\n",
    "\n",
    "foragers = forager_lives_short.index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = random.randint(0, forager_lives_short.shape[0])\n",
    "foragers = forager_lives_short.index \n",
    "bee = foragers[j]\n",
    "ax = sns.lineplot(data=trips_by_ages.loc[bee])\n",
    "ax.set(ylim=[-3,200], xlim=[0,60])\n",
    "plt.axvline(x=forager_lives_short.loc[bee].foraging_min_age.days, color='k', linestyle='--', linewidth=1)\n",
    "plt.axvline(x=forager_lives_short.loc[bee].foraging_max_age.days, color='k', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel('Day of life')\n",
    "ax.set_ylabel('Number of trips')\n",
    "ax.set_title('Number of trips by day, for bee #'+str(foragers[j])+\"\\n with first and last known forage marked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 2a: bee age vs average trip lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_trip_lengths = []\n",
    "for lenghts in rolled_trip_lengths:\n",
    "    if len(lenghts) == 0:\n",
    "        avg_trip_lengths += [0]\n",
    "    else:\n",
    "        avg = np.average(lenghts)\n",
    "        avg_trip_lengths += [avg]\n",
    "\n",
    "avg_trip_lengths_with_age = pd.concat([pd.Series(bee_days_since_birth),pd.Series(avg_trip_lengths)], axis=1)\n",
    "avg_trip_lengths_with_age.columns=['bee age','average trip length']\n",
    "\n",
    "avg_trip_lengths_with_age = avg_trip_lengths_with_age.groupby('bee age')['average trip length'].mean().reset_index()\n",
    "\n",
    "# Convert triplength from intervals to minutes\n",
    "avg_trip_lengths_with_age['average trip length'] = avg_trip_lengths_with_age['average trip length']/num_intervals_per_minute\n",
    "\n",
    "avg_trip_lengths_with_age.plot(x='bee age',y='average trip length',style='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 3: heatmap (histogram) of amount of trip lengths by age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty dataframe for the amount of triplengths occuring for each age of the bees\n",
    "triplength_age_df=pd.DataFrame(0, index=sorted(list(set(bee_days_since_birth))), columns=sorted(list(set(flat_list))))\n",
    "\n",
    "#Creating a Counter which holds the amount of triplengths for each bee\n",
    "counts = Counter()\n",
    "for bee in range (len(bee_days_since_birth)):\n",
    "    counts[bee] = Counter(rolled_trip_lengths[bee])\n",
    "    \n",
    "    \n",
    "for counter_index in range(len(bee_days_since_birth)):\n",
    "    for counter_triplength, counter_amount in counts[counter_index].items():\n",
    "        triplength_age_df.loc[bee_days_since_birth[counter_index], counter_triplength] += counter_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplength_age_df = triplength_age_df.drop(pd.np.nan)\n",
    "#converting intervalls to minutes\n",
    "triplength_age_df.columns = triplength_age_df.columns/num_intervals_per_minute\n",
    "triplength_age_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.log1p(triplength_age_df)\n",
    "plt.figure(figsize=(30,10))\n",
    "sns.heatmap(a, annot=False, fmt=\".1f\")\n",
    "#TODO: create also a normalized version of the heatmap (divide values by amount of bees with that age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized by number of bees with that specific age \n",
    "triplength_age_normalized_df = triplength_age_df\n",
    "\n",
    "ages = []\n",
    "for age in triplength_age_normalized_df.index:\n",
    "    ages.append(1/bee_days_since_birth.count(age))\n",
    "\n",
    "triplength_age_normalized_df = triplength_age_normalized_df.mul(ages, axis=0)\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "\n",
    "sns.heatmap(np.log1p(triplength_age_normalized_df), annot=False, fmt=\".1f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 4: boxplot of amount of trip lengths by age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependency of counts, might be needed to be moved up to work with multiple dataframes\n",
    "boxplot_df = pd.DataFrame()\n",
    "for age in counts:\n",
    "    if len(sorted(counts[age].elements()))>0:\n",
    "        temp = pd.DataFrame({\n",
    "            bee_days_since_birth[age]:sorted(counts[age].elements())})\n",
    "        if bee_days_since_birth[age] in boxplot_df.columns:\n",
    "            boxplot_df = boxplot_df.append(temp, ignore_index=True)\n",
    "        else:\n",
    "            boxplot_df = pd.concat([boxplot_df, temp], axis=1)\n",
    "boxplot_df = boxplot_df.reindex(sorted(boxplot_df.columns), axis=1)\n",
    "\n",
    "#rearranging the NaNs to the bottom\n",
    "arr = boxplot_df.values\n",
    "arr.sort(axis=0)\n",
    "#converting intervals to minutes\n",
    "boxplot_df = boxplot_df/num_intervals_per_minute\n",
    "boxplot_df = pd.DataFrame(arr, index=boxplot_df.index, columns=boxplot_df.columns).dropna(axis=0, how=\"all\")\n",
    "boxplot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_df.plot.box(xticks=[10,20,30,40,50,60,70,80,90,100,125,150,175,200,225,250,300,350,400,450], figsize=(30,15),vert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_df.plot.box(sym=\"\", figsize=(30,15),vert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap for Hivecoordinates when starting trips by amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_starts = calc_trip_starts(rolled, total_num_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create coordinate dataframe\n",
    "coordinate_df = pd.DataFrame(index=range(0,400),columns=range(0,250))\n",
    "coordinate_sub_10_df = pd.DataFrame(index=range(0,400),columns=range(0,250))\n",
    "coordinate_sub_20_df = pd.DataFrame(index=range(0,400),columns=range(0,250))\n",
    "coordinate_sub_30_df = pd.DataFrame(index=range(0,400),columns=range(0,250))\n",
    "coordinate_sub_40_df = pd.DataFrame(index=range(0,400),columns=range(0,250))\n",
    "coordinate_above_40_df = pd.DataFrame(index=range(0,400),columns=range(0,250))\n",
    "\n",
    "coordinate_df[:] = 0\n",
    "coordinate_sub_10_df[:] = 0\n",
    "coordinate_sub_20_df[:] = 0\n",
    "coordinate_sub_30_df[:] = 0\n",
    "coordinate_sub_40_df[:] = 0\n",
    "coordinate_above_40_df[:] = 0\n",
    "# travers trip_starts and lookup the coordinates for the respective bee for each trip start - write it into the coordinate dataframe\n",
    "for i in range(len(trip_starts)):\n",
    "    for j in range(len(trip_starts[i])):\n",
    "        #print(i, trip_starts[i][j],  end=' ')\n",
    "        if presence_locations_df.iat[i,trip_starts[i][j]] != \"0.0\" and \",\" in presence_locations_df.iat[i,trip_starts[i][j]]:\n",
    "            temp=presence_locations_df.iat[i,trip_starts[i][j]]\n",
    "            coordinates=[int(s) for s in temp.replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\"\").replace(\"-\",\"\").split() if s.isdigit()]\n",
    "            coordinate_df.iat[coordinates[0],coordinates[1]] +=1\n",
    "            if bee_days_since_birth[i] < 10 :\n",
    "                coordinate_sub_10_df.iat[coordinates[0],coordinates[1]] +=1\n",
    "            elif bee_days_since_birth[i] < 20 :\n",
    "                coordinate_sub_20_df.iat[coordinates[0],coordinates[1]] +=1\n",
    "            elif bee_days_since_birth[i] < 30 :\n",
    "                coordinate_sub_30_df.iat[coordinates[0],coordinates[1]] +=1\n",
    "            elif bee_days_since_birth[i] < 40 :\n",
    "                coordinate_sub_40_df.iat[coordinates[0],coordinates[1]] +=1\n",
    "            elif bee_days_since_birth[i] >= 40 :\n",
    "                coordinate_above_40_df.iat[coordinates[0],coordinates[1]] +=1\n",
    "# plot the coordinate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "\n",
    "sns.heatmap(np.log1p(coordinate_df), annot=False, fmt=\".1f\")\n",
    "#sns.heatmap(coordinate_df, annot=False, fmt=\".1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "\n",
    "#sns.heatmap(np.log1p(coordinate_sub_10_df), annot=False, fmt=\".1f\")\n",
    "sns.heatmap(coordinate_sub_10_df, annot=False, fmt=\".1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "\n",
    "#sns.heatmap(np.log1p(coordinate_sub_20_df), annot=False, fmt=\".1f\")\n",
    "sns.heatmap(coordinate_sub_20_df, annot=False, fmt=\".1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "\n",
    "#sns.heatmap(np.log1p(coordinate_sub_30_df), annot=False, fmt=\".1f\")\n",
    "sns.heatmap(coordinate_sub_30_df, annot=False, fmt=\".1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "\n",
    "#sns.heatmap(np.log1p(coordinate_sub_40_df), annot=False, fmt=\".1f\")\n",
    "sns.heatmap(coordinate_sub_40_df, annot=False, fmt=\".1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "\n",
    "sns.heatmap(np.log1p(coordinate_above_40_df), annot=False, fmt=\".1f\")\n",
    "#sns.heatmap(coordinate_above_40_df, annot=False, fmt=\".1f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Variables\n",
    "\n",
    "### Import Variables\n",
    "\n",
    "connect_str : String data for accessing the database\n",
    "\n",
    "meta        : contains meta data from bb_utils about bees that is used to get the data about forager bees\n",
    "\n",
    "### Parameters\n",
    "\n",
    "num_hours                    : Number of hours loaded from the database (int)\n",
    "\n",
    "datetime_start               : Starting point in the database (Datetime(y,m,d,h))\n",
    "\n",
    "bin_size_in_hours            : TBD\n",
    "\n",
    "num_intervals_per_hour       : How many intervals for a single hour the dataframes will have (int)\n",
    "\n",
    "rolling_window_size          : How big is the window for the rolling median function to filter noise (int)\n",
    "\n",
    "total_num_intervals          : How many intervals are there in total - calculated with the product of num_hours and num_intervals_per_hour\n",
    "\n",
    "group_id                     : ID of the forager group of bees that gets loaded \n",
    "\n",
    "bee_ids_as_beesbookid_format : Bee IDs from the chosen forager group in beesbookid format\n",
    "\n",
    "bee_ids_from_group           : Bee IDs from the chosen forager group in ferwa format (which is also used in the database)\n",
    "\n",
    "bee_days_since_birth         : Age of every chosen bee (Array of Int)\n",
    "\n",
    "csv_path        : Filepath to csv file with the presence dataframe, containing the bee ids and their detections within given intervalls for a given timeframe (Str)\n",
    "\n",
    "date_string                  : Filename for saving trips_df into a csv file\n",
    "\n",
    "\n",
    "### Dataframes\n",
    "\n",
    "presence_df             : contains the Bee IDs and and their detections (0 or 1) within given intervalls for a given amount of hours, starting from datetime_start\n",
    "\n",
    "presence_df_with_offset : presence_df with rolling_window_offset times copied first and last column, so the rolling median operation doesn't calculate NaN values. Used copies of the first and last column as neutral elements, since all 0s or 1s could have caused false information about trip starts or endings\n",
    "\n",
    "rolled                  : presence_df table after the filtering of noise with a rolling median window\n",
    "\n",
    "diffed                  : dataframe that only contains 1 and -1 for each bee when a trip starts or ends - calculated by the diff function applied to the rolled dataframe\n",
    "\n",
    "diffed_with_id          : diffed dataframe with an additional column containing the bee ids\n",
    "\n",
    "diffed_with_age         : diffed dataframe with an additional column containing the bee ages\n",
    "\n",
    "trips_df                : dataframe containing the amount of trips for each bee for each hour\n",
    "\n",
    "triplength_age_df       : dataframe containing the amount of each occuring triplength in relation to the age of the bees\n",
    "\n",
    "### to be named\n",
    "\n",
    "trip_lengths            : List of trip lengths for each bee (List of Lists of Int)\n",
    "\n",
    "curr_bee_trip_lenghts   : List of trip lengths for current bee (List of Int)\n",
    "\n",
    "curr_trip_length        : amount of trips for the current bee within the loop; used to prevent appending empty lists to trip_lengths (Int)\n",
    "\n",
    "bool_is_present         : 0 or 1 depending wether the bee has a detection within an interval or not (boolean)\n",
    "\n",
    "flat_list               : Conversion of trip_lengths into a normal list containing all the triplengths (List of Int)\n",
    "\n",
    "flat_series             : Conversion of flat_list into pd.Series (Series of Int)\n",
    "\n",
    "rolling_window_offset   : Size of the offset required for the rolling window to each side of the center - calculated by the floor of the windowsize devided by 2 (Int)\n",
    "\n",
    "first_col               : first column of presence_df, is used to duplicate it for the rolling_window_offset (Series of Int)\n",
    "\n",
    "last_col                : last column of presence_df, is used to duplicate it for the rolling_window_offset (Series of Int)\n",
    "\n",
    "counts                  : Array of Counters which contain the triplength and the amount. Each Position in the array represents one element of bee_days_since_birth (meaning one                                 certain age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caching the diffed tables - one time only\n",
    "#diffed = diffed.reset_index()\n",
    "#for i in range(num_days_to_process):\n",
    "#    print(i*4096, i*4096+4095)\n",
    "#    temp_cache_df = diffed.loc[i*4096:i*4096+4095,:]\n",
    "#    date_string = (datetime_start + timedelta(days=i)).strftime(\"%Y-%m-%d_%H\")\n",
    "#    csv_name = 'Diffed-'+str(date_string)+\"_num_hours_\"+str(num_hours)+\"_int_size_\"+str(num_intervals_per_hour)+'.csv'\n",
    "#    temp_path = \"../caches/Diffed/\"+csv_name\n",
    "#    temp_cache_df.to_csv(temp_path)\n",
    "#    print(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'presence_locations_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4e00cc20e409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loc_x_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresence_locations_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_loc_x_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_loc_y_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresence_locations_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_loc_y_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrip_starts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'presence_locations_df' is not defined"
     ]
    }
   ],
   "source": [
    "test_loc_x_df = presence_locations_df.copy()\n",
    "test_loc_x_df.loc[:,:] = 0.0\n",
    "test_loc_y_df = presence_locations_df.copy()\n",
    "test_loc_y_df.loc[:,:] = 0.0\n",
    "for i in range(len(trip_starts)):\n",
    "    for j in range(len(trip_starts[i])):\n",
    "        #print(i, trip_starts[i][j],  end=' ')\n",
    "        if presence_locations_df.iat[i,trip_starts[i][j]] != \"0.0\" and \",\" in presence_locations_df.iat[i,trip_starts[i][j]]:\n",
    "            temp=presence_locations_df.iat[i,trip_starts[i][j]]\n",
    "            coordinates=[int(s) for s in temp.replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\"\").replace(\"-\",\"\").split() if s.isdigit()]\n",
    "            test_loc_x_df.iat[i,trip_starts[i][j]] = coordinates[0]\n",
    "            test_loc_y_df.iat[i,trip_starts[i][j]] = coordinates[1]\n",
    "print(test_loc_x_df.replace(0,np.NaN).mean(axis=1))\n",
    "print(test_loc_y_df.replace(0,np.NaN).mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_loc_y_df.replace(0,np.NaN).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

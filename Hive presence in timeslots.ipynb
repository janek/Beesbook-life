{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each bee id, be able to provide the number of detections in the hive in the given timeslot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import math\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from datetime import timedelta, datetime\n",
    "import time\n",
    "\n",
    "import bb_utils\n",
    "import bb_utils.meta\n",
    "import bb_utils.ids\n",
    "import bb_backend\n",
    "from bb_backend.api import FramePlotter, VideoPlotter\n",
    "from bb_backend.api import get_plot_coordinates, transform_axis_coordinates, get_image_origin\n",
    "\n",
    "bb_backend.api.server_adress = 'localhost:8000'\n",
    "connect_str = \"\"\"dbname='beesbook' user='reader' host='tonic.imp.fu-berlin.de' \n",
    "                 password='' application_name='mehmed'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-08-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#Parameters for loading data\n",
    "num_hours = 24\n",
    "datetime_start = datetime(2016, 8, 23)\n",
    "\n",
    "#Parameters for presenting data\n",
    "bin_size_in_hours = 1\n",
    "\n",
    "#Hyperparameters for the data wrangling process\n",
    "num_intervals_per_hour = 120\n",
    "rolling_window_size = 7\n",
    "\n",
    "\n",
    "print(datetime_start)\n",
    "#(First detections are on 20.07.2016, last are 19.09.2016 (3 months duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-08-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#Define bee IDs by getting a known forager group\n",
    "meta = bb_utils.meta.BeeMetaInfo()\n",
    "\n",
    "group_id = 20\n",
    "bee_ids_from_group = map(lambda i: i.as_ferwar(), \n",
    "                list(map(bb_utils.ids.BeesbookID.from_dec_12, meta.get_foragergroup(group_id).dec12)))\n",
    "\n",
    "bee_ids_from_group = list(bee_ids_from_group)\n",
    "group = meta.get_foragergroup(group_id)\n",
    "print(group.date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from saved CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_detections(csv:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /mnt/storage/janek/2016-08-23_00:00:00.csv before the loop\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>bee_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-08-23 00:27:31.780472</td>\n",
       "      <td>3073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-08-23 00:27:32.116578</td>\n",
       "      <td>3073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-23 00:27:32.447851</td>\n",
       "      <td>3073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-08-23 00:27:32.783652</td>\n",
       "      <td>3073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-08-23 00:27:33.109483</td>\n",
       "      <td>3073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  bee_id\n",
       "0 2016-08-23 00:27:31.780472    3073\n",
       "1 2016-08-23 00:27:32.116578    3073\n",
       "2 2016-08-23 00:27:32.447851    3073\n",
       "3 2016-08-23 00:27:32.783652    3073\n",
       "4 2016-08-23 00:27:33.109483    3073"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for testing: a single csv with hardcoded name\n",
    "#sample_df = pd.read_csv('2016-08-23_00:00:00.csv', parse_dates=['timestamp'])\n",
    "\n",
    "location_prefix = \"/mnt/storage/janek/\" # or \"\"\n",
    "\n",
    "#Loading first element before the loop, to have a table formatted nicely for appending\n",
    "start_csv_name = (datetime_start).strftime(\"%Y-%m-%d_%H:%M:%S\")+\".csv\"\n",
    "\n",
    "print('Processing '+location_prefix+start_csv_name+' before the loop')\n",
    "detections_df = pd.read_csv(location_prefix+start_csv_name, parse_dates=['timestamp'], usecols=['timestamp', 'bee_id'])\n",
    "\n",
    "detections_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2016-08-23_01:00:00.csv\n",
      "Num. rows after appending: 6795262\n",
      "Processing 2016-08-23_02:00:00.csv\n",
      "Num. rows after appending: 10195578\n",
      "Processing 2016-08-23_03:00:00.csv\n",
      "Num. rows after appending: 13643441\n",
      "Processing 2016-08-23_04:00:00.csv\n",
      "Num. rows after appending: 17171049\n",
      "Processing 2016-08-23_05:00:00.csv\n",
      "Num. rows after appending: 20520678\n",
      "Processing 2016-08-23_06:00:00.csv\n",
      "Num. rows after appending: 22617753\n",
      "Processing 2016-08-23_07:00:00.csv\n",
      "Num. rows after appending: 25885315\n",
      "Processing 2016-08-23_08:00:00.csv\n",
      "Num. rows after appending: 29422176\n",
      "Processing 2016-08-23_09:00:00.csv\n",
      "Num. rows after appending: 32896095\n",
      "Processing 2016-08-23_10:00:00.csv\n",
      "Num. rows after appending: 36475063\n",
      "Processing 2016-08-23_11:00:00.csv\n",
      "Num. rows after appending: 40180078\n",
      "Processing 2016-08-23_12:00:00.csv\n",
      "Num. rows after appending: 43288399\n",
      "Processing 2016-08-23_13:00:00.csv\n",
      "Num. rows after appending: 46654242\n",
      "Processing 2016-08-23_14:00:00.csv\n",
      "Num. rows after appending: 50162001\n",
      "Processing 2016-08-23_15:00:00.csv\n",
      "Num. rows after appending: 53717490\n",
      "Processing 2016-08-23_16:00:00.csv\n",
      "Num. rows after appending: 57314149\n",
      "Processing 2016-08-23_17:00:00.csv\n",
      "Num. rows after appending: 60939786\n",
      "Processing 2016-08-23_18:00:00.csv\n",
      "Num. rows after appending: 64345086\n",
      "Processing 2016-08-23_19:00:00.csv\n",
      "Num. rows after appending: 67555807\n",
      "Processing 2016-08-23_20:00:00.csv\n",
      "Num. rows after appending: 70851863\n",
      "Processing 2016-08-23_21:00:00.csv\n",
      "Num. rows after appending: 74189084\n",
      "Processing 2016-08-23_22:00:00.csv\n",
      "Num. rows after appending: 77391086\n",
      "Processing 2016-08-23_23:00:00.csv\n",
      "Num. rows after appending: 80688851\n"
     ]
    }
   ],
   "source": [
    "#read and concat a number of hour-long csvs (note: thekla memory crashes if >16)\n",
    "for i in range(1, num_hours):\n",
    "    csv_name = (datetime_start + timedelta(hours=i)).strftime(\"%Y-%m-%d_%H:%M:%S\")+\".csv\"\n",
    "    print('Processing '+csv_name)\n",
    "    new_data = pd.read_csv(location_prefix+csv_name, parse_dates=['timestamp'], usecols=['timestamp', 'bee_id'])\n",
    "    detections_df = pd.concat([detections_df, new_data])\n",
    "    print('Num. rows after appending: '+str(detections_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80688851, 2)\n"
     ]
    }
   ],
   "source": [
    "print(detections_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interval length is the total observation period divided by total number of intervals\n",
    "total_num_intervals = (num_intervals_per_hour*num_hours)\n",
    "interval_length = timedelta(hours=num_hours) // (num_intervals_per_hour*num_hours)\n",
    "\n",
    "# prepare dataframe with zeros in the shape [bees x total_num_intervals]\n",
    "# append bee_ids from the left\n",
    "intervals = pd.DataFrame(data=np.zeros([len(bee_ids_from_group),total_num_intervals])) \n",
    "bee_ids = pd.DataFrame(data={'id': bee_ids_from_group})\n",
    "presence_df = pd.concat([bee_ids, intervals], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:15: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#Iterate over intervals and over detections\n",
    "#If a bee from bee_ids is detected within a given interval, mark the cell for that bee and interval with a '1'\n",
    "\n",
    "interval_starttime = datetime_start\n",
    "# print(\"Processing intervals: \")\n",
    "for interval in range(total_num_intervals): \n",
    "    #choose detections for interval\n",
    "    interval_endtime = interval_starttime + interval_length\n",
    "    before = detections_df['timestamp'] >= interval_starttime \n",
    "    after = detections_df['timestamp'] < interval_endtime\n",
    "    interval_detections = detections_df[before & after]\n",
    "    bee_row_number = 0\n",
    "    for bee in presence_df['id']: \n",
    "        if bee in interval_detections['bee_id'].unique():\n",
    "            presence_df.set_value(bee_row_number, interval, 1)\n",
    "        bee_row_number += 1 \n",
    "    interval_starttime = interval_endtime\n",
    "    #print(interval,\", \", end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure the length of the trip intervals\n",
    "presence_temp2 = presence_df.iloc[:, 1:]\n",
    "presence_temp2.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trip_lengths = []\n",
    "\n",
    "for bee in range(0, presence_temp2.shape[0]):\n",
    "    curr_trip_length = 0\n",
    "    curr_bee_trip_lenghts = []\n",
    "    #fill with trip lengths\n",
    "    for interval in range(total_num_intervals):\n",
    "        \n",
    "\n",
    "        #get the 0/1 value from presence_df at the given (bee, interval)\n",
    "        bool_is_present = presence_temp2.get_value(bee, interval)\n",
    "\n",
    "        if bool_is_present == 0.0: #bee not present in this interval\n",
    "            if curr_trip_length != 0: #if we had a value for a trip length, add it to trips and reset the counter\n",
    "                curr_bee_trip_lenghts.append(curr_trip_length)\n",
    "                curr_trip_length = 0\n",
    "        if bool_is_present == 1.0: #bee present in this interval, make the trip longer\n",
    "            curr_trip_length += 1\n",
    "    trip_lengths.append(curr_bee_trip_lenghts)\n",
    "    \n",
    "\n",
    "# print(trip_lengths)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trip_lengths)\n",
    "\n",
    "np.savetxt('trip_lengths.txt', trip_lengths, fmt='%d')\n",
    "# b = np.loadtxt('test1.txt', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply rolling median to filter noise\n",
    "#clean up to get rid of the NaNs\n",
    "#use diff to identify entries (with 1) and exits (with -1)\n",
    "#(sum_of_abs / 2) gives us the presumed number of trips a bee takes \n",
    "\n",
    "#'clean up nans'\n",
    "num_nans_to_clean = math.floor(rolling_window_size/2)\n",
    "\n",
    "first_col = presence_df.iloc[:, 1:2]\n",
    "last_col = presence_df.iloc[:, -1:]\n",
    "\n",
    "\n",
    "presence_temp = presence_df.iloc[:, 1:]\n",
    "# presence = presence_df.iloc[:, 1:]\n",
    "for i in range(0,num_nans_to_clean):\n",
    "    presence_temp = pd.concat([first_col, presence_temp, last_col] ,axis=1)\n",
    "\n",
    "rolled = presence_temp.rolling(window=rolling_window_size,center=True,axis=1).median()\n",
    "rolled = rolled.iloc[:, num_nans_to_clean:-num_nans_to_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffed = rolled.diff(axis=1)\n",
    "diffed.iloc[:,0] = np.zeros([11,1]) #clean out a column of NaNs \n",
    "diffed.head()\n",
    "\n",
    "#a copy to be used to preview rolled + diffed presence \n",
    "#not actually used in further calculations (they are just based on 'diffed')\n",
    "presence_df_copy = presence_df\n",
    "presence_df_copy.iloc[:, 1:] = diffed \n",
    "\n",
    "trips_df = presence_df['id'] #for combining results in one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence_df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loop config\n",
    "bin_starttime = datetime_start\n",
    "num_intervals_per_bin = num_intervals_per_hour*bin_size_in_hours\n",
    "total_num_bins = int(num_hours / bin_size_in_hours)\n",
    "\n",
    "print(\"num_intervals_per_bin: \", num_intervals_per_bin, \"total_num_bins: \", total_num_bins)\n",
    "for bin_nr in range(total_num_bins): \n",
    "    \n",
    "    start_index = bin_nr*num_intervals_per_bin\n",
    "    end_index = start_index + num_intervals_per_bin\n",
    "    \n",
    "    new_bin = diffed.iloc[:, start_index:end_index]\n",
    "    \n",
    "    #limit down to the right bin:\n",
    "    #read num_intervals_per_hour*bin_size_per_hour columns (as each column represents one interval)\n",
    "    \n",
    "    summed = new_bin.abs().sum(axis=1) / 2\n",
    "    summed.name = bin_nr\n",
    "    trips_df = pd.concat([trips_df,summed],axis=1) #add this interval to the trips table\n",
    "    #update loop index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_ser = pd.Series(np.array(trips_df.mean(axis=0))[1:])\n",
    "trips_ser.plot(kind='bar')\n",
    "# trips_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving (name still incomplete)\n",
    "date_string = (datetime_start).strftime(\"%Y-%m-%d_%H:%M:%S\")+\".csv\"\n",
    "trips_df.to_csv('/mnt/storage/janek/'+'TRIPS-'+date_string+'-'+'h'+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

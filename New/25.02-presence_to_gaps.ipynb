{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T10:35:46.193532Z",
     "start_time": "2019-02-05T10:35:45.526868Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import random\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from skimage.morphology import rectangle, closing\n",
    "from bb_behavior import db as bbdb;\n",
    "import bb_behavior\n",
    "import bb_utils\n",
    "sys.path.append('/home/mi/rrszynka/mnt/janek/Beesbook-janek/Python-modules/') #For bee_helpers, file_helpers and cache\n",
    "from bee_cache import Cache, CacheType, CacheFormat; c = Cache()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_confidence_requirement = 0.2 # 0.2 // 0.99\n",
    "offset_from_middle_seconds = datetime.timedelta(seconds=60)\n",
    "meta = bb_utils.meta.BeeMetaInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "presences = c.load_multiple_day_caches(detection_confidence_requirement=detection_confidence_requirement) # 0.99 / 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/60 [01:08<1:07:50, 68.99s/it]\u001b[A\n",
      "  3%|▎         | 2/60 [02:26<1:09:12, 71.59s/it]\u001b[A\n",
      "  5%|▌         | 3/60 [03:47<1:10:44, 74.47s/it]\u001b[A\n",
      "  7%|▋         | 4/60 [05:20<1:14:30, 79.83s/it]\u001b[A\n",
      "  8%|▊         | 5/60 [06:51<1:16:21, 83.30s/it]\u001b[A\n",
      " 10%|█         | 6/60 [08:09<1:13:34, 81.75s/it]\u001b[A\n",
      " 12%|█▏        | 7/60 [09:22<1:09:47, 79.00s/it]\u001b[A\n",
      " 13%|█▎        | 8/60 [10:43<1:08:54, 79.52s/it]\u001b[A\n",
      " 15%|█▌        | 9/60 [12:11<1:09:50, 82.17s/it]\u001b[A\n",
      " 17%|█▋        | 10/60 [13:45<1:11:23, 85.66s/it]\u001b[A\n",
      " 18%|█▊        | 11/60 [15:27<1:13:57, 90.55s/it]\u001b[A\n",
      " 20%|██        | 12/60 [17:16<1:16:50, 96.06s/it]\u001b[A\n",
      " 22%|██▏       | 13/60 [19:03<1:18:00, 99.58s/it]\u001b[A\n",
      " 23%|██▎       | 14/60 [20:48<1:17:34, 101.19s/it]\u001b[A\n",
      " 25%|██▌       | 15/60 [22:28<1:15:27, 100.62s/it]\u001b[A\n",
      " 27%|██▋       | 16/60 [24:10<1:14:09, 101.13s/it]\u001b[A\n",
      " 28%|██▊       | 17/60 [25:39<1:09:56, 97.60s/it] \u001b[A\n",
      " 30%|███       | 18/60 [27:04<1:05:37, 93.75s/it]\u001b[A\n",
      " 32%|███▏      | 19/60 [28:30<1:02:30, 91.48s/it]\u001b[A\n",
      " 33%|███▎      | 20/60 [29:46<57:50, 86.77s/it]  \u001b[A\n",
      " 35%|███▌      | 21/60 [31:29<59:29, 91.52s/it]\u001b[A\n",
      " 37%|███▋      | 22/60 [33:22<1:02:09, 98.15s/it]\u001b[A\n",
      " 38%|███▊      | 23/60 [35:34<1:06:47, 108.32s/it]\u001b[A\n",
      " 40%|████      | 24/60 [37:50<1:09:55, 116.54s/it]\u001b[A\n",
      " 42%|████▏     | 25/60 [39:58<1:10:01, 120.05s/it]\u001b[A\n",
      " 43%|████▎     | 26/60 [42:02<1:08:43, 121.28s/it]\u001b[A\n",
      " 45%|████▌     | 27/60 [43:26<1:00:32, 110.09s/it]\u001b[A\n",
      " 47%|████▋     | 28/60 [44:26<50:42, 95.07s/it]   \u001b[A\n",
      " 48%|████▊     | 29/60 [45:22<42:58, 83.18s/it]\u001b[A\n",
      " 50%|█████     | 30/60 [46:21<38:02, 76.07s/it]\u001b[A\n",
      " 52%|█████▏    | 31/60 [47:18<33:54, 70.17s/it]\u001b[A\n",
      " 53%|█████▎    | 32/60 [48:15<30:53, 66.18s/it]\u001b[A\n",
      " 55%|█████▌    | 33/60 [49:18<29:27, 65.45s/it]\u001b[A\n",
      " 57%|█████▋    | 34/60 [50:23<28:13, 65.13s/it]\u001b[A\n",
      " 58%|█████▊    | 35/60 [51:16<25:42, 61.72s/it]\u001b[A\n",
      " 60%|██████    | 36/60 [52:07<23:18, 58.26s/it]\u001b[A\n",
      " 62%|██████▏   | 37/60 [52:48<20:19, 53.04s/it]\u001b[A\n",
      " 63%|██████▎   | 38/60 [53:24<17:36, 48.00s/it]\u001b[A\n",
      " 65%|██████▌   | 39/60 [53:31<12:33, 35.87s/it]\u001b[A\n",
      " 67%|██████▋   | 40/60 [53:42<09:24, 28.24s/it]\u001b[A\n",
      " 68%|██████▊   | 41/60 [54:13<09:11, 29.02s/it]\u001b[A\n",
      " 70%|███████   | 42/60 [54:40<08:32, 28.49s/it]\u001b[A\n",
      " 72%|███████▏  | 43/60 [55:05<07:45, 27.40s/it]\u001b[A\n",
      " 73%|███████▎  | 44/60 [55:26<06:48, 25.51s/it]\u001b[A\n",
      " 75%|███████▌  | 45/60 [55:46<05:58, 23.93s/it]\u001b[A\n",
      " 77%|███████▋  | 46/60 [56:04<05:10, 22.19s/it]\u001b[A\n",
      " 78%|███████▊  | 47/60 [56:22<04:31, 20.87s/it]\u001b[A\n",
      " 80%|████████  | 48/60 [56:38<03:51, 19.29s/it]\u001b[A\n",
      " 82%|████████▏ | 49/60 [56:51<03:11, 17.41s/it]\u001b[A\n",
      " 83%|████████▎ | 50/60 [57:03<02:39, 15.96s/it]\u001b[A\n",
      " 85%|████████▌ | 51/60 [57:15<02:13, 14.81s/it]\u001b[A\n",
      " 87%|████████▋ | 52/60 [57:25<01:46, 13.36s/it]\u001b[A\n",
      " 88%|████████▊ | 53/60 [57:34<01:23, 11.91s/it]\u001b[A\n",
      " 90%|█████████ | 54/60 [57:42<01:04, 10.73s/it]\u001b[A\n",
      " 92%|█████████▏| 55/60 [57:49<00:48,  9.67s/it]\u001b[A\n",
      " 93%|█████████▎| 56/60 [57:55<00:34,  8.52s/it]\u001b[A\n",
      " 95%|█████████▌| 57/60 [58:00<00:22,  7.39s/it]\u001b[A\n",
      " 97%|█████████▋| 58/60 [58:03<00:12,  6.23s/it]\u001b[A\n",
      " 98%|█████████▊| 59/60 [58:06<00:05,  5.27s/it]\u001b[A\n",
      "100%|██████████| 60/60 [58:08<00:00,  4.34s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "gaps_list = []\n",
    "for (date, presence) in tqdm(presences):\n",
    "    npdate = np.datetime64(date)\n",
    "    gaps = make_gaps_for_presence(presence, date)\n",
    "    gaps_list.append((date, gaps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gaps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-20\n",
      "2016-07-21\n",
      "2016-07-22\n",
      "2016-07-23\n",
      "2016-07-24\n",
      "2016-07-25\n",
      "2016-07-26\n",
      "2016-07-27\n",
      "2016-07-28\n",
      "2016-07-29\n",
      "2016-07-30\n",
      "2016-07-31\n",
      "2016-08-01\n",
      "2016-08-02\n",
      "2016-08-03\n",
      "2016-08-04\n",
      "2016-08-05\n",
      "2016-08-06\n",
      "2016-08-07\n",
      "2016-08-08\n",
      "2016-08-10\n",
      "2016-08-11\n",
      "2016-08-12\n",
      "2016-08-13\n",
      "2016-08-14\n",
      "2016-08-15\n",
      "2016-08-16\n",
      "2016-08-18\n",
      "2016-08-19\n",
      "2016-08-20\n",
      "2016-08-21\n",
      "2016-08-22\n",
      "2016-08-23\n",
      "2016-08-24\n",
      "2016-08-25\n",
      "2016-08-26\n",
      "2016-08-27\n",
      "2016-08-28\n",
      "2016-08-29\n",
      "2016-08-30\n",
      "2016-08-31\n",
      "2016-09-01\n",
      "2016-09-02\n",
      "2016-09-03\n",
      "2016-09-04\n",
      "2016-09-05\n",
      "2016-09-06\n",
      "2016-09-07\n",
      "2016-09-08\n",
      "2016-09-09\n",
      "2016-09-10\n",
      "2016-09-11\n",
      "2016-09-12\n",
      "2016-09-13\n",
      "2016-09-14\n",
      "2016-09-15\n",
      "2016-09-16\n",
      "2016-09-17\n",
      "2016-09-18\n",
      "2016-09-19\n"
     ]
    }
   ],
   "source": [
    "conf_string = str(detection_confidence_requirement).replace('.','')\n",
    "for date, gaps in gaps_list:\n",
    "    print(date)\n",
    "    c.save(gaps, 'GAPS-'+str(date)+'_conf_'+conf_string, type=CacheType.gaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bee_id                                                              9\n",
       "age                                                                22\n",
       "age_group                                                           4\n",
       "exit                                              2016-07-20 00:16:00\n",
       "entry                                             2016-07-20 00:33:00\n",
       "gap_duration                                          0 days 00:17:00\n",
       "exit_x                                                        199.196\n",
       "exit_y                                                        98.5979\n",
       "exit_frame                                       13702865838643615097\n",
       "exit_closest_detection_timestamp     2016-07-20 00:16:00.269621+00:00\n",
       "cam_id_exit                                                         1\n",
       "hive_side_exit                                                      0\n",
       "entry_x                                                       122.803\n",
       "entry_y                                                       187.094\n",
       "entry_frame                                      14880238164766425437\n",
       "entry_closest_detection_timestamp    2016-07-20 00:32:59.977641+00:00\n",
       "cam_id_entry                                                        2\n",
       "hive_side_entry                                                     1\n",
       "origin_for_exit                                            [350, 250]\n",
       "origin_for_entry                                             [0, 250]\n",
       "hiveexit_distance_for_exit                                    213.692\n",
       "hiveexit_distance_for_entry                                   137.977\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaps_list[0][1].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_gaps = []\n",
    "for d, p in presences:\n",
    "    multi_gaps.append(c.load('GAPS-'+str(date)+'_conf_'+conf_string, type=CacheType.gaps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_gaps[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for presence in presences:\n",
    "    c.load('GAPS-'+str(date)+'_conf_'+conf_string, type=CacheType.gaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gaps_for_presence(presence, date):\n",
    "    # 1. Binarize presence\n",
    "    presence_bin = binarize_presence(presence)\n",
    "    \n",
    "    # 2. Detect gaps in presence (binarized)\n",
    "    gaps = []\n",
    "    for bee, bin_row in presence_bin.iterrows():\n",
    "        row = presence.loc[bee]\n",
    "        diff = np.diff(bin_row)\n",
    "        exits = np.where(diff == -1)[0]\n",
    "        entries = np.where(diff == 1)[0]\n",
    "\n",
    "        if len(exits) == 0 or len(entries) == 0:\n",
    "            continue\n",
    "\n",
    "        # if first entry is before firs exit, start with second entry\n",
    "        if entries[0] < exits[0]:\n",
    "            entries = entries[1:]\n",
    "            if len(entries) == 0:\n",
    "                continue\n",
    "\n",
    "        for exit, entry in zip(exits, entries):\n",
    "            duration = (entry - exit)\n",
    "            gaps.append((bee, exit, entry, duration))\n",
    "            \n",
    "    npdate = np.datetime64(date)\n",
    "    gaps = pd.DataFrame(gaps)\n",
    "    gaps.columns = ['bee_id', 'exit', 'entry', 'gap_duration']\n",
    "    gaps.exit = gaps.exit.apply(interval_to_timepoint_for_current_date)\n",
    "    gaps.entry = gaps.entry.apply(interval_to_timepoint_for_current_date)\n",
    "    gaps.gap_duration = gaps.gap_duration.apply(lambda intervals: pd.Timedelta(minutes=intervals / 2))\n",
    "    gaps.exit = gaps.exit.apply(to_datetime)\n",
    "    gaps.entry = gaps.entry.apply(to_datetime)\n",
    "    gaps['age'] = gaps.apply(row_to_age, axis=1)\n",
    "    gaps = gaps.dropna() #TODO: some ages are nan, which and why? (or just discard)\n",
    "    gaps['age_group'] = gaps.age.apply(lambda age: int(age) // 5) # Why does this throw warning?\n",
    "    gaps = gaps[['bee_id', 'age', 'age_group', 'exit', 'entry', 'gap_duration']]\n",
    "\n",
    "    # Add location, frame, cam and hive side information\n",
    "    for mode in ['exit', 'entry']:\n",
    "        new_info = make_dataframe_for_exits_entries(gaps, mode)\n",
    "        gaps = pd.merge(gaps, new_info, on=['bee_id', mode])\n",
    "\n",
    "    gaps['origin_for_exit'] = gaps.apply(origin_for_exit, axis=1)\n",
    "    gaps['origin_for_entry'] = gaps.apply(origin_for_entry, axis=1)\n",
    "    \n",
    "    # Calculate breakpoint distances\n",
    "    for mode in ['exit', 'entry']:\n",
    "        origin_x = [x for (x,y) in gaps['origin_for_'+mode]]\n",
    "        origin_y = [y for (x,y) in gaps['origin_for_'+mode]]\n",
    "\n",
    "        diff_x = gaps[mode+'_x'] - origin_x\n",
    "        diff_y = gaps[mode+'_y'] - origin_y\n",
    "\n",
    "        d = pd.Series(np.linalg.norm([diff_x, diff_y], axis=0))\n",
    "\n",
    "        gaps['hiveexit_distance_for_' + mode] = d\n",
    "    \n",
    "    return gaps   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: save (hdf/pkl/csv?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe_for_exits_entries(gaps, mode):\n",
    "    # Transform into a dict \n",
    "    gaps_dict = {}\n",
    "    for bee in gaps.bee_id.unique():\n",
    "        tsx = gaps[gaps.bee_id==bee][mode]\n",
    "        gaps_dict[int(bee)] = tsx\n",
    "\n",
    "    \n",
    "    subset = gaps_dict #gaps_head_dict // gaps_dict // bee_exits_dict\n",
    "    all_data = []\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=16) as pool:\n",
    "        items = list(subset.items()) # list of tuples \n",
    "        items = [(bee_id, timestamp, mode) for (bee_id, timestamp) in items]\n",
    "        for sub_df in pool.map(get_data_for_bee_id_timestamps, items):\n",
    "            all_data += sub_df\n",
    "            \n",
    "    all_data = [row for row in all_data if row != None]\n",
    "    all_data_df = pd.DataFrame(all_data, columns=[\"bee_id\", mode, mode+\"_x\", mode+\"_y\", mode+'_frame', mode+'_closest_detection_timestamp', \"cam_id_\"+mode])\n",
    "\n",
    "    def to_hive_side(cam_id):\n",
    "        if cam_id is None or pd.isnull(cam_id):\n",
    "            return 2\n",
    "        return cam_id // 2\n",
    "    \n",
    "    all_data_df['hive_side_'+mode] = all_data_df['cam_id_'+mode].apply(to_hive_side).astype(np.int)\n",
    "\n",
    "    \n",
    "    return all_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_bee_id_timestamps(args):\n",
    "    bee_id, timestamps, mode = args\n",
    "    offset = offset_from_middle_seconds\n",
    "    \n",
    "    with bb_behavior.db.DatabaseCursorContext() as cursor:\n",
    "        cursor.execute(\"PREPARE fetch_cam_id AS \"\n",
    "                       \"SELECT cam_id, x_pos_hive, y_pos_hive, frame_id, timestamp, ABS(EXTRACT(epoch FROM (timestamp - $4))) as diff FROM bb_detections_2016_stitched \"\n",
    "                       \"WHERE bee_id = $1 \"\n",
    "                       \"AND timestamp >= $2 and timestamp <= $3 \"\n",
    "                       \"ORDER BY diff ASC \"\n",
    "                       \"LIMIT 10 \"\n",
    "                      )\n",
    "        \n",
    "        def fetch_cam_id_and_location(bee_id, ts, cursor):\n",
    "            cursor.execute(\"EXECUTE fetch_cam_id(%s, %s, %s, %s)\", (bee_id, ts - offset, ts + offset, ts))\n",
    "            data = cursor.fetchall()\n",
    "            if data is None or len(data) == 0:\n",
    "                return None\n",
    "            \n",
    "            any_cam_id = data[0][0]\n",
    "            locations = np.array([d[1:3] for d in data if d[0] == any_cam_id])\n",
    "            \n",
    "            frame_id = data[0][3]\n",
    "            timestamp = data[0][4]\n",
    "            \n",
    "            \n",
    "            return bee_id, ts, np.mean(locations, axis=0)[0], np.mean(locations, axis=0)[1], frame_id, timestamp, any_cam_id\n",
    "        \n",
    "\n",
    "        results = []\n",
    "        for ts in timestamps:\n",
    "            results.append(fetch_cam_id_and_location(bee_id, ts, cursor))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From pres_to_gaps\n",
    "def binarize_presence(presence_for_day_df):\n",
    "    # TODO: running this on an already-binarized series will return all zeros,\n",
    "    # (and that's not what we want) - changing the threshold solves it, but try sth else\n",
    "\n",
    "    ys = presence_for_day_df.copy()\n",
    "    index = ys.index\n",
    "    if ys[ys>1].sum().sum() == 0:\n",
    "        #Consider this already binarized, make no changes\n",
    "        return ys\n",
    "\n",
    "    ys[ys>90] = 90\n",
    "    ys[ys>45] = 90\n",
    "    ys[ys<=45] = 0 #TODO: consult: what should the threshold be\n",
    "    ys[ys==90] = 1\n",
    "    ys = closing(ys, rectangle(1,15))\n",
    "    ys = pd.DataFrame(ys, index=index)\n",
    "    ys.index.name = 'bee_id'\n",
    "    return ys\n",
    "\n",
    "#%%\n",
    "def plot_presence(a):\n",
    "    plt.figure(figsize=(26,7))\n",
    "    plt.title(\"Presence\")\n",
    "    axes = plt.gca()\n",
    "    plt.scatter(np.arange(0,len(a)), a, s=3)\n",
    "\n",
    "#%%\n",
    "def get_frame_id_for_timestamp_for_current_bee(dt):\n",
    "    bee_id = int(bee)\n",
    "    get_frame_id_for_bee_id_and_timestamp(bee_id, dt)\n",
    "\n",
    "#%%\n",
    "def get_frame_id_from_row(row):\n",
    "    bee_id = row.bee\n",
    "    dt = row.exit\n",
    "    return get_frame_id_for_bee_id_and_timestamp(bee_id, dt)\n",
    "\n",
    "#%%\n",
    "def interval_to_timepoint_for_current_date(interval_number):\n",
    "    # Date must already be np.datetime64, so as not to convert here (executed for every row)\n",
    "    return npdate + np.timedelta64(int(interval_number)*30, 's')\n",
    "\n",
    "#%%\n",
    "def row_to_age(row):\n",
    "    bb_id = bb_utils.ids.BeesbookID.from_dec_9(row.bee_id)\n",
    "    age = meta.get_age(bb_id, row.exit).days\n",
    "    return age\n",
    "\n",
    "#%%\n",
    "def origin_for_exit(row):\n",
    "    origin = np.array([0, 250]) if row['hive_side_exit'] == 1 else np.array([350, 250])\n",
    "    return origin\n",
    "\n",
    "#%%\n",
    "def origin_for_entry(row):\n",
    "    origin = np.array([0, 250]) if row['hive_side_entry'] == 1 else np.array([350, 250])\n",
    "    return origin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unused here, potentially useful elsewhere \n",
    "def to_datetime(ts):\n",
    "    if ts.tzinfo is None or ts.tzinfo.utcoffset(ts) is None:\n",
    "        return ts\n",
    "    else:\n",
    "        return pytz.UTC.localize(pd.Timestamp(ts).to_pydatetime(), pytz.UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
